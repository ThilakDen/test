{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLjleQCDIbX1DSbZohk6Of",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThilakDen/test/blob/main/flan_alpaca_fintune_my_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy --pre torch torchvision torchaudio --force-reinstall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWkOOzALoEpI",
        "outputId": "d7a31f0a-bfe0-4004-db4d-15345101a588"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.24.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch\n",
            "  Downloading torch-2.0.0-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading torchvision-0.15.1-cp39-cp39-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio\n",
            "  Downloading torchaudio-2.0.1-cp39-cp39-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 KB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sympy\n",
            "  Downloading sympy-1.12rc1-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 KB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0\n",
            "  Downloading triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.10.7-py3-none-any.whl (10 kB)\n",
            "Collecting networkx\n",
            "  Downloading networkx-3.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 KB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wheel\n",
            "  Using cached wheel-0.40.0-py3-none-any.whl (64 kB)\n",
            "Collecting setuptools\n",
            "  Using cached setuptools-67.6.1-py3-none-any.whl (1.1 MB)\n",
            "Collecting cmake\n",
            "  Downloading cmake-3.26.1-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lit\n",
            "  Downloading lit-16.0.0.tar.gz (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 KB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pillow!=8.3.*,>=5.3.0\n",
            "  Downloading Pillow-9.4.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting certifi>=2017.4.17\n",
            "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 KB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 KB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mpmath>=0.19\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: lit\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-16.0.0-py3-none-any.whl size=93601 sha256=32cd4c1459c7a1ff56b0b7eaeb474a256e9fd77217f7a668334404f114671caf\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/ee/80/1520ca86c3557f70e5504b802072f7fc3b0e2147f376b133ed\n",
            "Successfully built lit\n",
            "Installing collected packages: mpmath, lit, cmake, wheel, urllib3, typing-extensions, sympy, setuptools, pillow, nvidia-nccl-cu11, nvidia-cufft-cu11, nvidia-cuda-nvrtc-cu11, numpy, networkx, MarkupSafe, idna, filelock, charset-normalizer, certifi, requests, nvidia-nvtx-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, jinja2, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: cmake\n",
            "    Found existing installation: cmake 3.25.2\n",
            "    Uninstalling cmake-3.25.2:\n",
            "      Successfully uninstalled cmake-3.25.2\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.40.0\n",
            "    Uninstalling wheel-0.40.0:\n",
            "      Successfully uninstalled wheel-0.40.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.15\n",
            "    Uninstalling urllib3-1.26.15:\n",
            "      Successfully uninstalled urllib3-1.26.15\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.11.1\n",
            "    Uninstalling sympy-1.11.1:\n",
            "      Successfully uninstalled sympy-1.11.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.6.1\n",
            "    Uninstalling setuptools-67.6.1:\n",
            "      Successfully uninstalled setuptools-67.6.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 8.4.0\n",
            "    Uninstalling Pillow-8.4.0:\n",
            "      Successfully uninstalled Pillow-8.4.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.0\n",
            "    Uninstalling networkx-3.0:\n",
            "      Successfully uninstalled networkx-3.0\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.2\n",
            "    Uninstalling MarkupSafe-2.1.2:\n",
            "      Successfully uninstalled MarkupSafe-2.1.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.10.7\n",
            "    Uninstalling filelock-3.10.7:\n",
            "      Successfully uninstalled filelock-3.10.7\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 2.0.12\n",
            "    Uninstalling charset-normalizer-2.0.12:\n",
            "      Successfully uninstalled charset-normalizer-2.0.12\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2022.12.7\n",
            "    Uninstalling certifi-2022.12.7:\n",
            "      Successfully uninstalled certifi-2022.12.7\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.2\n",
            "    Uninstalling Jinja2-3.1.2:\n",
            "      Successfully uninstalled Jinja2-3.1.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.1+cu116\n",
            "    Uninstalling torchvision-0.14.1+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.1+cu116\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.13.1+cu116\n",
            "    Uninstalling torchaudio-0.13.1+cu116:\n",
            "      Successfully uninstalled torchaudio-0.13.1+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 2.0.0 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.2 which is incompatible.\n",
            "fastai 2.7.11 requires torch<1.14,>=1.7, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.2 certifi-2022.12.7 charset-normalizer-3.1.0 cmake-3.26.1 filelock-3.10.7 idna-3.4 jinja2-3.1.2 lit-16.0.0 mpmath-1.3.0 networkx-3.0 numpy-1.24.2 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 pillow-9.4.0 requests-2.28.2 setuptools-67.6.1 sympy-1.12rc1 torch-2.0.0 torchaudio-2.0.1 torchvision-0.15.1 triton-2.0.0 typing-extensions-4.5.0 urllib3-1.26.15 wheel-0.40.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5G5ky39hyXM",
        "outputId": "67ac8dee-795b-4dd3-bbba-3553288b85f9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "git version 2.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BdqtlG9boD2c"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content')"
      ],
      "metadata": {
        "id": "WYE75AGeh8Hc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cHZ3uhLziUUd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/declare-lab/flan-alpaca.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPYv6z1BiI-O",
        "outputId": "02067d46-3ea3-43f5-ebd3-bd37b236710c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'flan-alpaca' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets transformers evaluate scipy"
      ],
      "metadata": {
        "id": "R_KeRF31iVku"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6uTKYYrxn9Ti"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q rouge_score py7zr fire pydantic "
      ],
      "metadata": {
        "id": "bXPgMoW0igwe"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pytorch-lightning"
      ],
      "metadata": {
        "id": "cqa4m5u6irze"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U71Wk6nEi9uQ",
        "outputId": "898adcce-dcca-499c-f422-b6531eccbc8e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-ngx902xn\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-ngx902xn\n",
            "  Resolved https://github.com/huggingface/transformers to commit cd73b9a8c140fb74cd93187f5c3d380cfc308023\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (3.10.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (0.13.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (2.28.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (1.24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (0.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir -p data"
      ],
      "metadata": {
        "id": "9O5bmZoxjLye"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/tloen/alpaca-lora/main/alpaca_data_cleaned.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNf8ZXpjljCm",
        "outputId": "f82680b5-24c4-4426-8ef2-7ba44e0e4b40"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-30 08:31:07--  https://raw.githubusercontent.com/tloen/alpaca-lora/main/alpaca_data_cleaned.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22680910 (22M) [text/plain]\n",
            "Saving to: ‘alpaca_data_cleaned.json.1’\n",
            "\n",
            "alpaca_data_cleaned 100%[===================>]  21.63M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-03-30 08:31:07 (319 MB/s) - ‘alpaca_data_cleaned.json.1’ saved [22680910/22680910]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/main/alpaca_data.json -O data/alpaca.json\n",
        "!wget https://raw.githubusercontent.com/tloen/alpaca-lora/main/alpaca_data_cleaned.json -O data/alpaca_clean.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0jhre0Tlu96",
        "outputId": "915f2046-fc4f-407d-fe14-0842f1dabbd7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-30 08:31:07--  https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/main/alpaca_data.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22773992 (22M) [text/plain]\n",
            "Saving to: ‘data/alpaca.json’\n",
            "\n",
            "data/alpaca.json    100%[===================>]  21.72M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-03-30 08:31:07 (324 MB/s) - ‘data/alpaca.json’ saved [22773992/22773992]\n",
            "\n",
            "--2023-03-30 08:31:08--  https://raw.githubusercontent.com/tloen/alpaca-lora/main/alpaca_data_cleaned.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22680910 (22M) [text/plain]\n",
            "Saving to: ‘data/alpaca_clean.json’\n",
            "\n",
            "data/alpaca_clean.j 100%[===================>]  21.63M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-03-30 08:31:08 (366 MB/s) - ‘data/alpaca_clean.json’ saved [22680910/22680910]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/flan-alpaca/data_loading.py preprocess_alpaca \\\n",
        "--path_in data/alpaca_clean.json \\\n",
        "--path_out data/train.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0MPRs4hmGoc",
        "outputId": "db358e47-32e7-441b-8a40-6c770885aa74"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"alpaca_samples\": 51759,\n",
            "  \"with_context\": 19728\n",
            "}\n",
            "{\n",
            "  \"source\": \"How many planets are in our Solar System?\",\n",
            "  \"target\": \"Currently, there are eight known planets in our Solar System: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"Arrange the following countries in descending order of population size.\\nAustralia, China, Brazil\",\n",
            "  \"target\": \"China, Brazil, Australia\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"Summarize what you learned in the article in one sentence.\\nThe article discusses the importance of maintaining healthy, abundant soil to grow food with. It explains how soil is formed, its various components, and how it can protect against climate change.\",\n",
            "  \"target\": \"Healthy soil is crucial to growing food and helping to mitigate climate change, and is created by various components and processes.\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"Please state a conclusion that can be derived from the given statement.\\nThe number of citizens in the city has increased significantly in the last two years.\",\n",
            "  \"target\": \"The population of the city has grown rapidly in recent years.\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"Summarize the impacts of technology on education\\nhttps://www.educationsuperhighway.org/blog/technology-is-transforming-modern-education/\",\n",
            "  \"target\": \"Technology is changing the way modern education is delivered. It is enabling teachers to personalize learning experiences to meet the needs of individual students, providing access to the latest educational materials, and facilitating the use of real-time data to identify factors that can impact student success. Additionally, technology allows schools to collaborate with other institutions and create engaging, interactive classroom and virtual learning environments. Technology is also improving communication between students, parents, teachers, and administrators, as well as providing access to online tools that can help students learn in new and innovative ways.\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"Compose a song in C Major.\",\n",
            "  \"target\": \"Verse 1\\nC  G  F  C\\nB-flat  F  G  C\\n\\nChorus\\nC  G  A-minor  F\\nC  G  A-minor  F\\n\\nVerse 2\\nC  G  D  G\\nA-minor  D  G  C\\n\\nChorus\\nC  G  A-minor  F\\nC  G  A-minor  F\\n\\nBridge \\nF  D  G  C\\nA-minor  D  A-minor  F\\n\\nChorus\\nC  G  A-minor  F\\nC  G  A-minor  F\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"Suggest a way to reduce energy consumption in households.\",\n",
            "  \"target\": \"One way to reduce energy consumption in households is to install energy-efficient appliances such as ENERGY STAR appliances. Additionally, households can switch to Energy Star certified light bulbs, use programmable thermostats to regulate temperature settings, and unplug or turn off appliances when not in use. Other changes that can help reduce energy consumption include using natural light during daytime hours, installing solar panels, and taking advantage of utility company programs such as off-peak pricing.\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"Explain the conservation of momentum.\",\n",
            "  \"target\": \"The law of conservation of momentum states that the total momentum of a closed system remains constant, regardless of any internal exchange of momentum between the components. This means that the momentum of a group of objects will remain the same, regardless of how they interact with each other. It can be applied to many situations, including collisions and explosions, provided they occur in an isolated closed system. In a collision, the momentum of both objects remains the same, though the direction may change. In an explosion, the change in momentum is equal to the sum of the individual momentums of the new components, as each piece originally had zero momentum.\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"Explain what the blue pill and the red pill symbolize in the movie \\\"The Matrix\\\".\",\n",
            "  \"target\": \"In the movie \\\"The Matrix\\\", the blue pill and the red pill symbolize the choice between accepting the illusion of reality or discovering the truth. The blue pill represents accepting what is presented to be reality and living an oblivious life, while the red pill symbolizes the courage to accept the hard truths and unlock new possibilities.\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"List three ways in which technology has transformed the field of education.\",\n",
            "  \"target\": \"1. Technology has enabled remote learning, allowing students to access high quality education from anywhere in the world.\\n2. AI-assisted learning platforms can personalize instruction based on a student\\u2019s unique learning style, making education more efficient and productive.\\n3. Online collaboration tools have made it easy for students to work together to complete projects and assignments, fostering teamwork and communication skills.\"\n",
            "}\n",
            "{\n",
            "  \"total_samples\": 51759,\n",
            "  \"source\": \"{'min': 5, 'max': 597, 'median': 17, '95_percentile': 41}\",\n",
            "  \"target\": \"{'min': 2, 'max': 993, 'median': 44, '95_percentile': 162}\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/flan-alpaca/training.py --output_dir outputs/model/base \\\n",
        "--use_compile \\\n",
        "--train_epochs 3 \\\n",
        "--data_path data/train.json \\\n",
        "--model_name_or_path \"google/flan-t5-small\" \\\n",
        "--train_batch_size 1 \\\n",
        "--gradient_accumulation_steps 64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA2wMVuSmgw_",
        "outputId": "a31cdbaf-0c21-4ed1-f4e7-130e8011e9d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-30 08:34:34.590275: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-30 08:34:34.590394: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-30 08:34:34.590414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Global seed set to 42\n",
            "\"data_path\":                   data/train.json\n",
            "\"debug\":                       False\n",
            "\"gradient_accumulation_steps\": 64\n",
            "\"learning_rate\":               0.0005\n",
            "\"max_source_length\":           40\n",
            "\"max_target_length\":           160\n",
            "\"model_name_or_path\":          google/flan-t5-small\n",
            "\"output_dir\":                  outputs/model/base\n",
            "\"seed\":                        42\n",
            "\"train_batch_size\":            1\n",
            "\"train_epochs\":                3\n",
            "\"use_compile\":                 True\n",
            "\"use_fsdp\":                    False\n",
            "\"use_gradient_checkpointing\":  False\n",
            "\"weight_decay\":                0.0\n",
            "{'orig_state_dict': 192}\n",
            "Using 16bit Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type            | Params\n",
            "------------------------------------------\n",
            "0 | model | OptimizedModule | 77.0 M\n",
            "------------------------------------------\n",
            "77.0 M    Trainable params\n",
            "0         Non-trainable params\n",
            "77.0 M    Total params\n",
            "307.845   Total estimated model params size (MB)\n",
            "Epoch 0:   0% 0/51759 [00:00<?, ?it/s] [2023-03-30 08:35:18,286] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
            "Epoch 0:  32% 16760/51759 [20:51<43:33, 13.39it/s, loss=nan.0]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "   trainer = pl.Trainer(\n",
        "        precision=\"16-mixed\",\n",
        "\n",
        "        line 212 , praning.py"
      ],
      "metadata": {
        "id": "vb_41eITqAk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "You can copy all the data from your Google Colab notebook to your Google Drive using the following steps:\n",
        "\n",
        "Mount your Google Drive to the Colab notebook using the following code snippet:\n",
        "\n",
        "javascript\n",
        "Copy code\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "This will prompt you to authenticate and give permission to access your Google Drive.\n",
        "\n",
        "Navigate to the directory where the data you want to copy is located in the Colab notebook using the cd command.\n",
        "\n",
        "Use the cp command to copy the data to your Google Drive directory. For example, if you want to copy a file called data.csv from the Colab directory to your Google Drive directory, you can use the following command:\n",
        "\n",
        "bash\n",
        "Copy code\n",
        "!cp data.csv /content/drive/MyDrive/\n",
        "This will copy the data.csv file to the root directory of your Google Drive.\n",
        "\n",
        "If you want to copy an entire directory and its contents, you can use the -r option with the cp command. For example:\n",
        "\n",
        "bash\n",
        "Copy code\n",
        "!cp -r my_directory /content/drive/MyDrive/\n",
        "This will copy the my_directory directory and its contents to the root directory of your Google Drive.\n",
        "\n",
        "Once the data has been copied, you can unmount your Google Drive by running the following code:\n",
        "\n",
        "scss\n",
        "Copy code\n",
        "drive.flush_and_unmount()\n",
        "This will ensure that all data has been properly saved to your Google Drive before unmounting it.\n",
        "\n",
        "By following these steps, you can easily copy all the data from your Colab notebook to your Google Drive for safekeeping or further analysis."
      ],
      "metadata": {
        "id": "U1tvGBkjuDrE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}